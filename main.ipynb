{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function: Sigmoid with clipping to prevent overflow\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "\n",
    "# Derivative of Sigmoid\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Neural Network class with 2 hidden layers\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n",
    "        # Initialize weights and biases\n",
    "        self.weights_input_hidden1 = 2 * np.random.rand(input_size, hidden1_size) - 1\n",
    "        self.bias_hidden1 = 2 * np.random.rand(hidden1_size) - 1\n",
    "        self.weights_hidden1_hidden2 = 2 * np.random.rand(hidden1_size, hidden2_size) - 1\n",
    "        self.bias_hidden2 = 2 * np.random.rand(hidden2_size) - 1\n",
    "        self.weights_hidden2_output = 2 * np.random.rand(hidden2_size, output_size) - 1\n",
    "        self.bias_output = 2 * np.random.rand(output_size) - 1\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Forward propagation\n",
    "        self.hidden1_input = np.dot(inputs, self.weights_input_hidden1) + self.bias_hidden1\n",
    "        self.hidden1_output = sigmoid(self.hidden1_input)\n",
    "        self.hidden2_input = np.dot(self.hidden1_output, self.weights_hidden1_hidden2) + self.bias_hidden2\n",
    "        self.hidden2_output = sigmoid(self.hidden2_input)\n",
    "        self.output_layer_input = np.dot(self.hidden2_output, self.weights_hidden2_output) + self.bias_output\n",
    "        self.output = sigmoid(self.output_layer_input)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, inputs, expected_output, learning_rate):\n",
    "        # Calculate error\n",
    "        output_error = expected_output - self.output\n",
    "        output_delta = output_error * sigmoid_derivative(self.output)\n",
    "\n",
    "        hidden2_error = output_delta.dot(self.weights_hidden2_output.T)\n",
    "        hidden2_delta = hidden2_error * sigmoid_derivative(self.hidden2_output)\n",
    "\n",
    "        hidden1_error = hidden2_delta.dot(self.weights_hidden1_hidden2.T)\n",
    "        hidden1_delta = hidden1_error * sigmoid_derivative(self.hidden1_output)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.weights_hidden2_output += self.hidden2_output.T.dot(output_delta) * learning_rate\n",
    "        self.bias_output += np.sum(output_delta, axis=0) * learning_rate\n",
    "        self.weights_hidden1_hidden2 += self.hidden1_output.T.dot(hidden2_delta) * learning_rate\n",
    "        self.bias_hidden2 += np.sum(hidden2_delta, axis=0) * learning_rate\n",
    "        self.weights_input_hidden1 += inputs.T.dot(hidden1_delta) * learning_rate\n",
    "        self.bias_hidden1 += np.sum(hidden1_delta, axis=0) * learning_rate\n",
    "\n",
    "        # Return the error for plotting\n",
    "        return np.sum(output_error**2) / len(inputs)\n",
    "\n",
    "    def train(self, inputs, expected_output, iterations, learning_rate):\n",
    "        errors = []\n",
    "        for i in range(iterations):\n",
    "            self.forward(inputs)\n",
    "            error = self.backward(inputs, expected_output, learning_rate)\n",
    "            errors.append(error)\n",
    "            # if i==iterations\n",
    "        print(error)\n",
    "        return errors\n",
    "    # def get_weights(self):\n",
    "    #     return self.weights_input_hidden1, self.weights_hidden1_hidden2, self.weights_hidden2_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = [line.strip().split() for line in file.readlines()]\n",
    "    return np.array(data, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = read_data('input.txt')\n",
    "expected_output = read_data('output.txt')\n",
    "expected_output = expected_output.reshape(-1, 3)  # Adjust this based on your output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38437874625982615\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Create neural network\n",
    "    input_size = 625\n",
    "    hidden1_size = 100\n",
    "    hidden2_size = 100\n",
    "    output_size = 3\n",
    "    \n",
    "    iterations = 100\n",
    "    learning_rate=1/(len(inputs))\n",
    "    \n",
    "    num_runs = 1\n",
    "    all_errors = []\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "        nn = NeuralNetwork(input_size, hidden1_size, hidden2_size, output_size)\n",
    "        errors = nn.train(inputs, expected_output, iterations, learning_rate)\n",
    "        all_errors.append(errors)\n",
    "    \n",
    "    # # Plot the error values on a logarithmic scale on the x-axis\n",
    "    # for i, errors in enumerate(all_errors):\n",
    "    #     plt.plot(errors, label=f'Run {i+1}')\n",
    "\n",
    "    # # plt.xscale('log')\n",
    "    # plt.xlabel('Iterations')\n",
    "    # plt.ylabel('Error')\n",
    "    # plt.title('Training Error over Iterations')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= read_data('test.txt')\n",
    "# test = test.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output:\n",
      "Circle: 91.40%, Square: 7.07%, Triangle: 1.52%\n",
      "Circle: 59.04%, Square: 38.19%, Triangle: 2.77%\n",
      "Circle: 21.95%, Square: 23.96%, Triangle: 54.08%\n",
      "Circle: 0.98%, Square: 40.00%, Triangle: 59.01%\n",
      "Circle: 15.75%, Square: 74.43%, Triangle: 9.81%\n",
      "Circle: 4.93%, Square: 62.15%, Triangle: 32.92%\n",
      "Circle: 9.54%, Square: 55.38%, Triangle: 35.08%\n",
      "Circle: 0.41%, Square: 51.12%, Triangle: 48.46%\n",
      "Circle: 1.27%, Square: 36.63%, Triangle: 62.10%\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted Output:\")\n",
    "res=nn.forward(test)\n",
    "for i in range(len(res)):\n",
    "    sum=res[i][0]+res[i][1]+res[i][2]\n",
    "    print(f\"Circle: {(res[i][0]/sum)*100:.2f}%, Square: {(res[i][1]/sum)*100:.2f}%, Triangle: {(res[i][2]/sum)*100:.2f}%\")\n",
    "# print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
